# Phase 4: Advanced Features (v3.8.0)

**Status**: ðŸš§ In Progress
**Prerequisites**: Phase 3 Temporal Memory Core, RAG & Learning Integration
**Goal**: Advanced temporal memory capabilities with ML-based learning

---

## Table of Contents

1. [Overview](#overview)
2. [Feature 1: Adaptive Decay](#feature-1-adaptive-decay)
3. [Feature 2: Contextual Retrieval](#feature-2-contextual-retrieval)
4. [Feature 3: Memory Consolidation](#feature-3-memory-consolidation)
5. [Feature 4: Retention Forecasting](#feature-4-retention-forecasting)
6. [Feature 5: Advanced Pattern Detection](#feature-5-advanced-pattern-detection)
7. [Feature 6: Multi-dimensional Persona](#feature-6-multi-dimensional-persona)
8. [Implementation Order](#implementation-order)
9. [Database Schema Changes](#database-schema-changes)
10. [API Reference](#api-reference)

---

## Overview

Phase 4 introduces 6 advanced features that enhance the temporal memory system with adaptive behavior, predictive capabilities, and sophisticated learning algorithms.

### Design Principles

- **Adaptive**: System learns optimal parameters per memory type
- **Predictive**: Forecast future retention states
- **Intelligent**: ML-based pattern recognition
- **Consolidating**: Prevent memory fragmentation
- **Comprehensive**: Full persona parameter learning

---

## Feature 1: Adaptive Decay

### Concept

Allow different memories to decay at different rates based on their content type, importance, and usage patterns.

### Formula

```
R(t) = max(min_retention, e^(-t/S_memory))
```

Where `S_memory` is determined per-memory instead of using global `base_strength`.

### Content Type Classification

Automatically classify memories into types with different decay strengths:

| Memory Type | S Value | Retention at 30d | Example |
|-------------|---------|------------------|---------|
| **Factual Knowledge** | 40.0 | 47% | Code syntax, definitions |
| **Procedural** | 30.0 | 37% | How to use tools, workflows |
| **Conversational** | 20.0 | 22% | Casual chat, preferences |
| **Ephemeral** | 10.0 | 5% | Temporary context, quick Q&A |

### Classification Logic

```rust
pub enum MemoryType {
    FactualKnowledge,  // S=40.0
    Procedural,        // S=30.0
    Conversational,    // S=20.0
    Ephemeral,         // S=10.0
}

impl MemoryType {
    pub fn classify(user_message: &str, ai_response: &str) -> Self {
        // Factual: Contains code, definitions, technical terms
        if ai_response.contains("```") ||
           ai_response.to_lowercase().contains("define") ||
           ai_response.to_lowercase().contains("means") {
            return MemoryType::FactualKnowledge;
        }

        // Procedural: Instructions, steps, how-to
        if ai_response.to_lowercase().contains("step") ||
           ai_response.to_lowercase().contains("first") ||
           ai_response.contains("1.") ||
           ai_response.to_lowercase().contains("how to") {
            return MemoryType::Procedural;
        }

        // Ephemeral: Short, no code, no instructions
        if ai_response.len() < 100 &&
           !ai_response.contains("```") {
            return MemoryType::Ephemeral;
        }

        // Default: Conversational
        MemoryType::Conversational
    }

    pub fn decay_strength(&self) -> f64 {
        match self {
            MemoryType::FactualKnowledge => 40.0,
            MemoryType::Procedural => 30.0,
            MemoryType::Conversational => 20.0,
            MemoryType::Ephemeral => 10.0,
        }
    }
}
```

### Database Changes

- Add `memory_type` TEXT column to `episodic_memory`
- Modify `decay_strength` to be set per-memory on creation

### Implementation Steps

1. âœ… Create `MemoryType` enum in `temporal_memory.rs`
2. âœ… Add classification logic
3. âœ… Update database schema to store `memory_type`
4. âœ… Modify memory creation to auto-classify
5. âœ… Update decay calculation to use per-memory S
6. âœ… Add Tauri command to manually override memory type

### API

```rust
// Auto-classify on creation
pub fn create_memory_with_classification(
    &self,
    user_message: &str,
    ai_response: &str,
) -> Result<String>;

// Manual override
#[tauri::command]
pub async fn temporal_set_memory_type(
    memory_id: String,
    memory_type: String,
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<(), String>;

// Get memory type
#[tauri::command]
pub async fn temporal_get_memory_type(
    memory_id: String,
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<String, String>;
```

---

## Feature 2: Contextual Retrieval

### Concept

Boost retention scores for memories related to the current conversation topic, making them more likely to be retrieved and preventing premature decay.

### Context Detection

```rust
pub struct ConversationContext {
    pub topics: Vec<String>,        // ["rust", "tauri", "database"]
    pub active_since: i64,          // Unix timestamp
    pub memory_ids: Vec<String>,    // Related memory IDs
}

impl ConversationContext {
    /// Extract topics from recent messages
    pub fn extract_topics(messages: &[String]) -> Vec<String> {
        // 1. Tokenize and clean
        // 2. Remove stop words
        // 3. Extract technical terms, code keywords
        // 4. Rank by TF-IDF
        // 5. Return top 5-10 topics
    }

    /// Find memories matching topics
    pub fn find_related_memories(
        &self,
        db: &Database,
    ) -> Result<Vec<String>> {
        // Search episodic_memory for topic keywords
        // Return memory IDs
    }
}
```

### Contextual Boost Formula

```rust
// Add context boost to retention calculation
pub fn calculate_retention_with_context(
    &self,
    days_elapsed: f64,
    decay_strength: f64,
    access_count: i32,
    is_pinned: bool,
    is_contextually_relevant: bool,
) -> f64 {
    let base_retention = self.calculate_retention(
        days_elapsed,
        decay_strength,
        access_count,
        is_pinned
    );

    if is_contextually_relevant {
        // Boost by 20%
        (base_retention * 1.2).min(1.0)
    } else {
        base_retention
    }
}
```

### Database Changes

- Create `conversation_context` table:
  - `id` INTEGER PRIMARY KEY
  - `topics` TEXT (JSON array)
  - `active_since` INTEGER
  - `related_memory_ids` TEXT (JSON array)
  - `created_at` INTEGER

### Implementation Steps

1. âœ… Create `ConversationContext` struct
2. âœ… Implement topic extraction (TF-IDF or keyword-based)
3. âœ… Create `conversation_context` table
4. âœ… Add context tracking to chat service
5. âœ… Modify retention calculation to include context boost
6. âœ… Update RAG retrieval to prioritize contextual memories
7. âœ… Add Tauri commands for context management

### API

```rust
#[tauri::command]
pub async fn temporal_set_context(
    topics: Vec<String>,
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<(), String>;

#[tauri::command]
pub async fn temporal_get_context(
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<ConversationContext, String>;

#[tauri::command]
pub async fn temporal_clear_context(
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<(), String>;
```

---

## Feature 3: Memory Consolidation

### Concept

Merge similar low-retention memories into consolidated entries to prevent memory fragmentation and preserve important information.

### Consolidation Criteria

Memories are candidates for consolidation if:
1. Retention score < 0.3 (low retention)
2. Semantic similarity > 0.85 (very similar content)
3. Created within 7 days of each other
4. Not pinned

### Consolidation Algorithm

```rust
pub struct MemoryConsolidator {
    embedding_service: Arc<EmbeddingService>,
    temporal_service: Arc<TemporalMemoryService>,
}

impl MemoryConsolidator {
    /// Find consolidation candidates
    pub fn find_candidates(&self) -> Result<Vec<ConsolidationGroup>> {
        // 1. Get all low-retention memories (< 0.3)
        // 2. Compute embeddings for each
        // 3. Cluster by similarity (DBSCAN or hierarchical)
        // 4. Return groups with similarity > 0.85
    }

    /// Consolidate a group of memories
    pub fn consolidate_group(
        &self,
        group: ConsolidationGroup,
    ) -> Result<String> {
        // 1. Combine user_message + ai_response from all memories
        // 2. Use LLM to summarize into consolidated memory
        // 3. Average satisfaction scores
        // 4. Sum access counts
        // 5. Set retention = 0.5 (fresh start)
        // 6. Mark as consolidated, link to originals
        // 7. Delete or archive original memories
        // 8. Return new consolidated memory ID
    }
}

pub struct ConsolidationGroup {
    pub memory_ids: Vec<String>,
    pub similarity: f64,
    pub combined_text: String,
    pub avg_satisfaction: f64,
    pub total_access_count: i32,
}
```

### Database Changes

- Add columns to `episodic_memory`:
  - `is_consolidated` BOOLEAN DEFAULT 0
  - `consolidated_from` TEXT (JSON array of original memory IDs)
  - `consolidation_date` INTEGER

### Implementation Steps

1. âœ… Create `MemoryConsolidator` service
2. âœ… Implement candidate finding (similarity clustering)
3. âœ… Implement LLM-based summarization
4. âœ… Update database schema for consolidation metadata
5. âœ… Add background task for periodic consolidation
6. âœ… Add Tauri commands for manual consolidation

### API

```rust
#[tauri::command]
pub async fn temporal_find_consolidation_candidates(
    service: State<'_, Arc<MemoryConsolidator>>,
) -> Result<Vec<ConsolidationGroup>, String>;

#[tauri::command]
pub async fn temporal_consolidate_memories(
    memory_ids: Vec<String>,
    service: State<'_, Arc<MemoryConsolidator>>,
) -> Result<String, String>;

#[tauri::command]
pub async fn temporal_get_consolidation_history(
    limit: usize,
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<Vec<ConsolidationRecord>, String>;
```

---

## Feature 4: Retention Forecasting

### Concept

Predict when memories will drop below critical retention thresholds, enabling proactive intervention.

### Forecast Calculation

```rust
pub struct RetentionForecast {
    pub memory_id: String,
    pub current_retention: f64,
    pub days_until_critical: Option<f64>,  // Days until < 0.3
    pub days_until_pruning: Option<f64>,   // Days until < 0.05
    pub predicted_trajectory: Vec<(i64, f64)>,  // (timestamp, retention)
}

impl TemporalMemoryService {
    /// Calculate when retention will drop below threshold
    pub fn forecast_retention(
        &self,
        memory_id: &str,
        threshold: f64,
    ) -> Result<RetentionForecast> {
        // 1. Get memory data (created_at, decay_strength, access_count, is_pinned)
        // 2. Calculate current retention
        // 3. Solve for t when R(t) = threshold
        //    threshold = e^(-t/S)
        //    ln(threshold) = -t/S
        //    t = -S * ln(threshold)
        // 4. Generate trajectory points for next 90 days
        // 5. Return forecast
    }

    /// Find memories at risk of pruning
    pub fn find_at_risk_memories(
        &self,
        days_ahead: f64,
        threshold: f64,
    ) -> Result<Vec<RetentionForecast>> {
        // Return memories that will drop below threshold within days_ahead
    }
}
```

### Mathematical Solution

Given:
- Current retention: `R(t) = e^(-t/S)`
- Target threshold: `R_target`

Solve for time `t` when `R(t) = R_target`:

```
R_target = e^(-t/S)
ln(R_target) = -t/S
t = -S * ln(R_target)
```

Example:
- S = 20.0
- R_target = 0.3 (critical)
- t = -20.0 * ln(0.3) = 24.08 days

### Database Changes

- Create `retention_forecasts` table (optional, for caching):
  - `memory_id` TEXT
  - `threshold` REAL
  - `days_until` REAL
  - `calculated_at` INTEGER

### Implementation Steps

1. âœ… Implement forecast calculation math
2. âœ… Add `forecast_retention()` method
3. âœ… Add `find_at_risk_memories()` method
4. âœ… Create trajectory generation
5. âœ… Add Tauri commands for forecasting
6. âœ… Create proactive alerts for at-risk memories

### API

```rust
#[tauri::command]
pub async fn temporal_forecast_retention(
    memory_id: String,
    threshold: f64,
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<RetentionForecast, String>;

#[tauri::command]
pub async fn temporal_find_at_risk_memories(
    days_ahead: f64,
    threshold: f64,
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<Vec<RetentionForecast>, String>;

#[tauri::command]
pub async fn temporal_get_forecast_trajectory(
    memory_id: String,
    days_ahead: f64,
    service: State<'_, Arc<TemporalMemoryService>>,
) -> Result<Vec<(i64, f64)>, String>;
```

---

## Feature 5: Advanced Pattern Detection

### Concept

Replace heuristic pattern detection in `learning.rs` with ML-based classification for more accurate persona trait extraction.

### Current Heuristic Approach (Phase 3)

```rust
// Simple keyword matching
let has_formal_words = ai_response.to_lowercase().contains("please");
let formality = if has_formal_words { 0.7 } else { 0.3 };
```

### ML-Based Approach (Phase 4)

#### Option 1: Local Lightweight Models

Use ONNX Runtime with small pre-trained models:

```rust
use ort::{Session, SessionBuilder, Value};

pub struct PatternDetector {
    formality_model: Session,
    technical_model: Session,
    emoji_model: Session,
}

impl PatternDetector {
    pub fn detect_formality(&self, text: &str) -> Result<f32> {
        // 1. Tokenize text
        // 2. Convert to embeddings
        // 3. Run through formality classifier
        // 4. Return score 0.0-1.0
    }

    pub fn detect_technical_depth(&self, text: &str) -> Result<f32> {
        // Similar process with technical classifier
    }
}
```

#### Option 2: Ollama-based Classification

Use existing Ollama service with structured prompts:

```rust
pub struct LlmPatternDetector {
    ollama_service: Arc<OllamaService>,
}

impl LlmPatternDetector {
    pub async fn analyze_traits(
        &self,
        text: &str,
    ) -> Result<TraitAnalysis> {
        let prompt = format!(
            r#"Analyze the following AI response and rate these traits from 0.0 to 1.0:

Response: "{}"

Output JSON format:
{{
  "formality": 0.0-1.0,
  "verbosity": 0.0-1.0,
  "technical_depth": 0.0-1.0,
  "emoji_usage": 0.0-1.0,
  "humor": 0.0-1.0,
  "empathy": 0.0-1.0,
  "proactivity": 0.0-1.0
}}
"#,
            text
        );

        let response = self.ollama_service.generate(prompt).await?;
        let traits: TraitAnalysis = serde_json::from_str(&response)?;
        Ok(traits)
    }
}
```

#### Recommendation

**Use Option 2 (Ollama-based)** because:
- No new dependencies
- Leverages existing Qwen model
- More flexible and interpretable
- Can analyze all traits in one pass
- Easier to debug and tune

### Implementation Steps

1. âœ… Create `LlmPatternDetector` service
2. âœ… Design analysis prompt template
3. âœ… Implement trait analysis method
4. âœ… Add batch analysis for multiple memories
5. âœ… Replace heuristic logic in `learning.rs`
6. âœ… Add caching for analyzed traits
7. âœ… Add Tauri commands for on-demand analysis

### API

```rust
#[tauri::command]
pub async fn learning_analyze_traits(
    text: String,
    service: State<'_, Arc<LlmPatternDetector>>,
) -> Result<TraitAnalysis, String>;

#[tauri::command]
pub async fn learning_batch_analyze(
    memory_ids: Vec<String>,
    service: State<'_, Arc<LlmPatternDetector>>,
) -> Result<Vec<TraitAnalysis>, String>;
```

---

## Feature 6: Multi-dimensional Persona

### Concept

Extend persona learning from 4 parameters to all 10 `PersonaParameters` fields using advanced pattern detection.

### Current Persona Parameters (Phase 3)

```rust
pub struct PersonaParameters {
    pub formality: f32,           // âœ… Learned
    pub verbosity: f32,           // âœ… Learned
    pub technical_depth: f32,     // âœ… Learned
    pub emoji_usage: f32,         // âœ… Learned
    pub humor: f32,               // âŒ Not learned
    pub creativity: f32,          // âŒ Not learned
    pub empathy: f32,             // âŒ Not learned
    pub assertiveness: f32,       // âŒ Not learned
    pub proactivity: f32,         // âŒ Not learned
    pub cultural_awareness: f32,  // âŒ Not learned
}
```

### Full Learning Implementation

```rust
impl LearningService {
    pub fn evolve_full_persona_from_temporal(
        &self,
        current_persona: PersonaParameters,
        retention_threshold: f32,
        learning_rate: f32,
    ) -> Result<PersonaParameters> {
        // 1. Get high-retention memories
        let high_retention_memories = self.get_high_retention_memories(retention_threshold)?;

        // 2. Analyze each memory with LlmPatternDetector
        let trait_analyses: Vec<TraitAnalysis> = high_retention_memories
            .iter()
            .map(|memory| {
                self.pattern_detector.analyze_traits(&memory.ai_response)
            })
            .collect::<Result<Vec<_>>>()?;

        // 3. Calculate weighted average for each trait
        let mut total_weight = 0.0;
        let mut weighted_sums = [0.0; 10];  // One per parameter

        for (analysis, memory) in trait_analyses.iter().zip(&high_retention_memories) {
            let weight = memory.retention_score * memory.satisfaction *
                         (1.0 + memory.access_count as f32 * 0.1);

            total_weight += weight;
            weighted_sums[0] += analysis.formality * weight;
            weighted_sums[1] += analysis.verbosity * weight;
            weighted_sums[2] += analysis.technical_depth * weight;
            weighted_sums[3] += analysis.emoji_usage * weight;
            weighted_sums[4] += analysis.humor * weight;
            weighted_sums[5] += analysis.creativity * weight;
            weighted_sums[6] += analysis.empathy * weight;
            weighted_sums[7] += analysis.assertiveness * weight;
            weighted_sums[8] += analysis.proactivity * weight;
            weighted_sums[9] += analysis.cultural_awareness * weight;
        }

        // 4. Normalize
        let learned_traits: [f32; 10] = weighted_sums
            .iter()
            .map(|sum| (sum / total_weight).clamp(0.0, 1.0))
            .collect::<Vec<_>>()
            .try_into()
            .unwrap();

        // 5. Gradual blending
        let evolved = PersonaParameters {
            formality: clamp(
                current_persona.formality * (1.0 - learning_rate) +
                learned_traits[0] * learning_rate,
                0.0, 1.0
            ),
            verbosity: clamp(
                current_persona.verbosity * (1.0 - learning_rate) +
                learned_traits[1] * learning_rate,
                0.0, 1.0
            ),
            // ... repeat for all 10 parameters
        };

        Ok(evolved)
    }
}
```

### TraitAnalysis Structure

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TraitAnalysis {
    pub formality: f32,
    pub verbosity: f32,
    pub technical_depth: f32,
    pub emoji_usage: f32,
    pub humor: f32,
    pub creativity: f32,
    pub empathy: f32,
    pub assertiveness: f32,
    pub proactivity: f32,
    pub cultural_awareness: f32,
}
```

### Database Changes

- Create `trait_analysis_cache` table:
  - `memory_id` TEXT PRIMARY KEY
  - `traits` TEXT (JSON TraitAnalysis)
  - `analyzed_at` INTEGER

### Implementation Steps

1. âœ… Create `TraitAnalysis` struct with all 10 fields
2. âœ… Update `LlmPatternDetector` to analyze all traits
3. âœ… Create `trait_analysis_cache` table
4. âœ… Implement caching logic
5. âœ… Replace `evolve_persona_from_temporal_memory()` with full version
6. âœ… Add Tauri commands for persona evolution
7. âœ… Test learning convergence

### API

```rust
#[tauri::command]
pub async fn learning_evolve_full_persona(
    retention_threshold: f32,
    learning_rate: f32,
    service: State<'_, Arc<LearningService>>,
) -> Result<PersonaParameters, String>;

#[tauri::command]
pub async fn learning_get_trait_cache(
    memory_id: String,
    service: State<'_, Arc<LearningService>>,
) -> Result<Option<TraitAnalysis>, String>;

#[tauri::command]
pub async fn learning_clear_trait_cache(
    service: State<'_, Arc<LearningService>>,
) -> Result<usize, String>;
```

---

## Implementation Order

**Priority order based on dependencies:**

1. **Adaptive Decay** (Foundational)
   - Required by: Retention Forecasting
   - Dependencies: None
   - Estimated effort: 2-3 hours

2. **Retention Forecasting** (Mathematical)
   - Required by: Contextual Retrieval, Memory Consolidation
   - Dependencies: Adaptive Decay
   - Estimated effort: 2 hours

3. **Advanced Pattern Detection** (ML Infrastructure)
   - Required by: Multi-dimensional Persona
   - Dependencies: None
   - Estimated effort: 3-4 hours

4. **Multi-dimensional Persona** (Learning)
   - Required by: None
   - Dependencies: Advanced Pattern Detection
   - Estimated effort: 2 hours

5. **Contextual Retrieval** (RAG Enhancement)
   - Required by: None
   - Dependencies: Retention Forecasting
   - Estimated effort: 3-4 hours

6. **Memory Consolidation** (Complex)
   - Required by: None
   - Dependencies: Retention Forecasting, Advanced Pattern Detection
   - Estimated effort: 4-5 hours

**Total estimated effort**: 16-20 hours

---

## Database Schema Changes

### New Columns for `episodic_memory`

```sql
ALTER TABLE episodic_memory ADD COLUMN memory_type TEXT DEFAULT 'conversational';
ALTER TABLE episodic_memory ADD COLUMN is_consolidated BOOLEAN DEFAULT 0;
ALTER TABLE episodic_memory ADD COLUMN consolidated_from TEXT;
ALTER TABLE episodic_memory ADD COLUMN consolidation_date INTEGER;
```

### New Tables

```sql
-- Conversation context tracking
CREATE TABLE IF NOT EXISTS conversation_context (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    topics TEXT NOT NULL,  -- JSON array
    active_since INTEGER NOT NULL,
    related_memory_ids TEXT,  -- JSON array
    created_at INTEGER NOT NULL,
    updated_at INTEGER NOT NULL
);

-- Trait analysis cache
CREATE TABLE IF NOT EXISTS trait_analysis_cache (
    memory_id TEXT PRIMARY KEY,
    traits TEXT NOT NULL,  -- JSON TraitAnalysis
    analyzed_at INTEGER NOT NULL,
    FOREIGN KEY (memory_id) REFERENCES episodic_memory(id) ON DELETE CASCADE
);

-- Consolidation history
CREATE TABLE IF NOT EXISTS consolidation_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    consolidated_memory_id TEXT NOT NULL,
    original_memory_ids TEXT NOT NULL,  -- JSON array
    similarity_score REAL NOT NULL,
    consolidation_method TEXT NOT NULL,
    created_at INTEGER NOT NULL,
    FOREIGN KEY (consolidated_memory_id) REFERENCES episodic_memory(id) ON DELETE CASCADE
);

-- Optional: Retention forecast cache
CREATE TABLE IF NOT EXISTS retention_forecasts (
    memory_id TEXT,
    threshold REAL,
    days_until REAL,
    calculated_at INTEGER,
    PRIMARY KEY (memory_id, threshold),
    FOREIGN KEY (memory_id) REFERENCES episodic_memory(id) ON DELETE CASCADE
);
```

### Indexes

```sql
CREATE INDEX IF NOT EXISTS idx_episodic_memory_type ON episodic_memory(memory_type);
CREATE INDEX IF NOT EXISTS idx_episodic_consolidated ON episodic_memory(is_consolidated);
CREATE INDEX IF NOT EXISTS idx_context_active_since ON conversation_context(active_since DESC);
CREATE INDEX IF NOT EXISTS idx_trait_cache_analyzed_at ON trait_analysis_cache(analyzed_at DESC);
```

---

## API Reference

### Adaptive Decay

```typescript
// Auto-classify and create memory (internal)
temporal_create_memory_with_classification(
  user_message: string,
  ai_response: string
): Promise<string>

// Manual memory type override
temporal_set_memory_type(
  memory_id: string,
  memory_type: 'factual' | 'procedural' | 'conversational' | 'ephemeral'
): Promise<void>

// Get memory type
temporal_get_memory_type(
  memory_id: string
): Promise<string>
```

### Contextual Retrieval

```typescript
// Set conversation context
temporal_set_context(
  topics: string[]
): Promise<void>

// Get current context
temporal_get_context(): Promise<ConversationContext>

// Clear context
temporal_clear_context(): Promise<void>
```

### Memory Consolidation

```typescript
// Find consolidation candidates
temporal_find_consolidation_candidates(): Promise<ConsolidationGroup[]>

// Consolidate specific memories
temporal_consolidate_memories(
  memory_ids: string[]
): Promise<string>  // Returns new consolidated memory ID

// Get consolidation history
temporal_get_consolidation_history(
  limit: number
): Promise<ConsolidationRecord[]>
```

### Retention Forecasting

```typescript
// Forecast single memory
temporal_forecast_retention(
  memory_id: string,
  threshold: number
): Promise<RetentionForecast>

// Find at-risk memories
temporal_find_at_risk_memories(
  days_ahead: number,
  threshold: number
): Promise<RetentionForecast[]>

// Get forecast trajectory
temporal_get_forecast_trajectory(
  memory_id: string,
  days_ahead: number
): Promise<Array<[number, number]>>  // [timestamp, retention]
```

### Advanced Pattern Detection

```typescript
// Analyze traits in text
learning_analyze_traits(
  text: string
): Promise<TraitAnalysis>

// Batch analyze memories
learning_batch_analyze(
  memory_ids: string[]
): Promise<TraitAnalysis[]>
```

### Multi-dimensional Persona

```typescript
// Evolve full persona from temporal memory
learning_evolve_full_persona(
  retention_threshold: number,
  learning_rate: number
): Promise<PersonaParameters>

// Get cached trait analysis
learning_get_trait_cache(
  memory_id: string
): Promise<TraitAnalysis | null>

// Clear trait cache
learning_clear_trait_cache(): Promise<number>  // Returns count cleared
```

---

## Next Steps

1. âœ… Review and approve this implementation plan
2. â³ **Start with Feature 1: Adaptive Decay**
3. â³ Implement remaining features in priority order
4. â³ Add comprehensive tests for each feature
5. â³ Create frontend integration for new APIs
6. â³ Update documentation
7. â³ Performance testing and optimization

---

## Success Criteria

- âœ… All 6 features implemented and tested
- âœ… Retention forecasting accurate within 5%
- âœ… Memory consolidation reduces storage by 20-30%
- âœ… ML pattern detection achieves >80% accuracy
- âœ… Full persona learning converges within 100 memories
- âœ… Build completes with 0 errors
- âœ… All APIs documented and tested
