/**
 * AI Manager Service
 * Orchestrates all AI services (Llama, Whisper, TTS)
 */

import log from 'electron-log';
import { getTTSService, cleanupTTSService } from './tts.service';
import { getWhisperService, cleanupWhisperService } from './whisper.service';
import type { PersonaParameters } from '@shared/types/persona.types';

export class AIManagerService {
  private ttsService = getTTSService();
  private whisperService = getWhisperService();
  private isInitialized = false;

  /**
   * Initialize all AI services
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) {
      log.info('AI Manager already initialized');
      return;
    }

    try {
      log.info('Initializing AI Manager...');

      // Initialize TTS (system native, always available)
      await this.ttsService.initialize();

      // Initialize Whisper (optional, requires model)
      try {
        await this.whisperService.initialize();
      } catch (error) {
        log.warn('Whisper initialization failed (will use placeholder):', error);
      }

      // Note: Llama service will be initialized on-demand when needed
      // to avoid long startup time

      this.isInitialized = true;
      log.info('AI Manager initialized successfully');
    } catch (error) {
      log.error('Failed to initialize AI Manager:', error);
      throw error;
    }
  }

  /**
   * Generate chat response
   * Uses placeholder response for now, will integrate Llama when model is available
   */
  async generateResponse(
    message: string,
    persona: PersonaParameters,
    _conversationHistory?: Array<{ role: 'user' | 'assistant'; content: string }>
  ): Promise<{ response: string; metrics?: { responseTime: number; tokens?: number } }> {
    const startTime = Date.now();

    try {
      log.info(`Generating response for: "${message.substring(0, 50)}..."`);

      // TODO: When Llama model is available, use it here
      // For now, generate a smart placeholder response based on persona

      const response = this.generatePlaceholderResponse(message, persona);
      const responseTime = Date.now() - startTime;

      log.info(`Response generated in ${responseTime}ms`);

      return {
        response,
        metrics: {
          responseTime,
          tokens: response.split(' ').length,
        },
      };
    } catch (error) {
      log.error('Failed to generate response:', error);
      throw error;
    }
  }

  /**
   * Generate placeholder response based on persona
   */
  private generatePlaceholderResponse(message: string, persona: PersonaParameters): string {
    const isKorean = true; // Default to Korean for now
    const isFormal = persona.formality > 60;
    const isHumorous = persona.humor > 50;
    const isVerbose = persona.verbosity > 60;

    // Detect message intent
    const isGreeting = /ì•ˆë…•|hello|hi|hey/i.test(message);
    const isQuestion = message.includes('?') || /ë¬´ì—‡|ì–´ë–»ê²Œ|ì™œ|what|how|why/i.test(message);
    const isCode = /ì½”ë“œ|code|í”„ë¡œê·¸ë˜ë°|programming/i.test(message);

    if (isKorean) {
      const honorific = isFormal ? 'ìš”' : '';

      if (isGreeting) {
        return isHumorous
          ? `ì•ˆë…•í•˜ì„¸${honorific}! ë°˜ê°€ì›Œ${honorific} ğŸŒŸ ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸${honorific}?`
          : `ì•ˆë…•í•˜ì„¸${honorific}. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œ${honorific}?`;
      }

      if (isQuestion) {
        const verbose = isVerbose ? 'ìì„¸íˆ ì„¤ëª…ë“œë¦¬ìë©´, ' : '';
        return `${verbose}ì¢‹ì€ ì§ˆë¬¸ì´ì—${honorific}! "${message}"ì— ëŒ€í•´ ${
          isVerbose ? 'ìƒì„¸í•˜ê²Œ' : ''
        } ë‹µë³€í•´ë“œë¦´ê²Œ${honorific}.\n\nğŸ’¡ ì°¸ê³ : í˜„ì¬ AI ëª¨ë¸ í†µí•© ì¤‘ì´ë¼ ì„ì‹œ ì‘ë‹µì„ ì œê³µí•˜ê³  ìˆì–´${honorific}. ê³§ ì‹¤ì œ AI ê¸°ëŠ¥ì´ ì¶”ê°€ë  ì˜ˆì •ì´ì—${honorific}!`;
      }

      if (isCode) {
        return `ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ì´ì‹œêµ°${honorific}! ${
          isVerbose ? 'í”„ë¡œê·¸ë˜ë°ì€ ì œê°€ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ë¶„ì•¼ ì¤‘ í•˜ë‚˜ì—${honorific}. ' : ''
        }ì‹¤ì œ AI ëª¨ë¸ì´ í†µí•©ë˜ë©´ ë” ì •í™•í•œ ì½”ë“œ ì§€ì›ì„ ì œê³µí•  ìˆ˜ ìˆì„ ê±°ì—${honorific}.\n\nì…ë ¥í•˜ì‹  ë‚´ìš©: "${message}"`;
      }

      return `ì•Œê² ${isVerbose ? 'ìŠµë‹ˆë‹¤' : 'ì–´${honorific}'}! "${message}"${
        isVerbose ? 'ì— ëŒ€í•´ ë§ì”€í•˜ì…¨êµ°ìš”' : ''
      }.\n\ní˜„ì¬ ì €ëŠ” ê°œë°œ ì¤‘ì´ë©°, ${
        isHumorous ? 'ì—´ì‹¬íˆ ë°°ìš°ëŠ” ì¤‘ì´ì—ìš” ğŸ“šâœ¨' : 'ê³§ ì™„ì „í•œ ê¸°ëŠ¥ì„ ì œê³µí•  ì˜ˆì •ì´ì—ìš”'
      }. ${isFormal ? 'ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.' : 'ê¸°ëŒ€í•´ì£¼ì„¸ìš”!'}`;
    } else {
      // English
      if (isGreeting) {
        return isHumorous
          ? `Hello! Nice to meet you! ğŸŒŸ How are you doing today?`
          : `Hello. How can I help you?`;
      }

      if (isQuestion) {
        const verbose = isVerbose ? 'Let me explain in detail. ' : '';
        return `${verbose}Great question about "${message}"! ${
          isVerbose ? 'I would love to provide a comprehensive answer. ' : ''
        }\n\nğŸ’¡ Note: I'm currently in development with AI model integration in progress. Full AI capabilities coming soon!`;
      }

      if (isCode) {
        return `A coding question! ${
          isVerbose ? 'Programming is one of my favorite topics. ' : ''
        }Once the AI model is integrated, I'll provide much better code assistance.\n\nYour input: "${message}"`;
      }

      const verboseExtra = isVerbose ? ' - I understand what you\'re asking about' : '';
      const devStatus = isHumorous ? 'and learning fast! ğŸ“šâœ¨' : 'and will soon have full AI capabilities';
      const closing = isFormal ? 'Please stay tuned.' : 'Stay tuned!';

      return `Got it! "${message}"${verboseExtra}.\n\nI'm currently under development ${devStatus}. ${closing}`;
    }
  }

  /**
   * Start voice recording
   */
  async startVoiceInput(): Promise<boolean> {
    try {
      await this.whisperService.startRecording();
      return true;
    } catch (error) {
      log.error('Failed to start voice input:', error);
      return false;
    }
  }

  /**
   * Stop voice recording and get transcript
   */
  async stopVoiceInput(): Promise<{ transcript: string; language: 'ko' | 'en' }> {
    try {
      return await this.whisperService.stopRecording();
    } catch (error) {
      log.error('Failed to stop voice input:', error);
      return { transcript: '', language: 'ko' };
    }
  }

  /**
   * Speak text using TTS
   */
  async speak(text: string): Promise<void> {
    try {
      await this.ttsService.speak(text);
    } catch (error) {
      log.error('Failed to speak text:', error);
      throw error;
    }
  }

  /**
   * Stop current TTS speech
   */
  async stopSpeaking(): Promise<void> {
    try {
      await this.ttsService.stop();
    } catch (error) {
      log.error('Failed to stop speaking:', error);
    }
  }

  /**
   * Get TTS voices
   */
  getTTSVoices(): string[] {
    return this.ttsService.getAvailableVoices();
  }

  /**
   * Cleanup all AI services
   */
  async cleanup(): Promise<void> {
    log.info('Cleaning up AI Manager...');

    await cleanupTTSService();
    await cleanupWhisperService();
    // Llama cleanup will be added when integrated

    this.isInitialized = false;
    log.info('AI Manager cleaned up');
  }
}

// Singleton instance
let aiManagerInstance: AIManagerService | null = null;

export function getAIManager(): AIManagerService {
  if (!aiManagerInstance) {
    aiManagerInstance = new AIManagerService();
  }
  return aiManagerInstance;
}

export async function cleanupAIManager(): Promise<void> {
  if (aiManagerInstance) {
    await aiManagerInstance.cleanup();
    aiManagerInstance = null;
  }
}
